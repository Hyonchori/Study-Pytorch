{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2c63994",
   "metadata": {},
   "source": [
    "# What is ```torch.nn``` really?\n",
    "- 파이토치는 상용자가 인공신경망을 직접 만들고 학습하는 것을 돕는 **```torch.nn, torch.optim, Dataset, DataLoader```** 모듈과 클래스를 제공함\n",
    "- 이 모듈을 자신의 문제에 제대로 사용하려면 이들의 동작 원리를 이해해야 함\n",
    "- 그 이해를 돕기 위해 **MNIST 데이터셋에 대해 기본적인 인공신경망을 학습해보겠음**\n",
    "- 처음엔 아무런 기능을 쓰지 않고 구현한 다음. **점차 위 모듈을 이용하면서 얼마나 쉽고 편해지는지 볼 것**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127bc32",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. MNIST data setup\n",
    "- **classic MNIST 데이터셋**을 사용할 것\n",
    "- 0~9 클래스의 손글씨 데이터가 흑백 이미지로 구성되어 있음\n",
    "- 여기선 **pathlib** 라이브러리를 이용하여 path 를 다루고 **request** 라이브러리를 이용하여 데이터셋을 다운받을 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218e3f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnsit\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "    content = requests.get(URL + FILENAME).content\n",
    "    (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b556f6",
   "metadata": {},
   "source": [
    "- numpy array 형식의 데이터셋이 pickle 을 이용해 저장됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6def0f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1ba828",
   "metadata": {},
   "source": [
    "- 각 이미지는 28x28 크기로 flatten 된 형태인 784 길이의 벡터로 저장되어 있음\n",
    "- 이를 reshape 하여 한 번 시각화하겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8618c3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4a4f6b",
   "metadata": {},
   "source": [
    "- 파이토치는 numpy 의 array 보다는 ```torch.tensor``` 형식의 데이터를 사용함\n",
    "- 이에 맞게 데이터를 변환하겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc66cc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "\n",
    "n, c = x_train.shape\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b2cdc",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Neural net from sctach (no torch.nn)\n",
    "- 우선 **Pytorch 의 tensor 연산을 이용하지 않고 인공신경망을 구현해 볼 것**\n",
    "- 파이토치는 간단한 linear 모델에 필요한 weight 나 bias 를 생성하기 위해 필요한 random 또는 0으로 채워진 텐서를 생성하는 메서드를 제공함.\n",
    "- 생성한 텐서의 ```requires_grad=True``` 로 설정하면 해당 텐서가 이용된 모든 연산을 추적하여 역전파하여 gradient 를 자동으로 계산할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fa7cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "weights = torch.randn(784, 10) / math.sqrt(784)    # Xavier initialization (dividing with 1/sqrt(n))\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896fb55d",
   "metadata": {},
   "source": [
    "- gradient 를 자동으로 계산할 수 있으므로 statndard Python function 을 이용하여 모델로 사용할 수 있음\n",
    "- 여기선 평범한 행렬곱과 broadcasted addition 을 작성하여 간단한 선형 모델을 만들어볼 것\n",
    "- **활성 함수** 도 필요한데 *log_softmax* 함수를 구현하여 사용할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d86ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f728d18c",
   "metadata": {},
   "source": [
    "- @ 는 dot product 를 의미\n",
    "- 데이터의 batch 에 대해서 위 함수를 호출할 수 있음\n",
    "- 이는 *한 번의 forward pass* 임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb0dc305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.5887, -2.3234, -2.1606, -2.3063, -2.3442, -2.2755, -2.0596, -2.4067,\n",
      "        -2.7051, -2.0487], grad_fn=<SelectBackward>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "xb = x_train[0: batch_size]\n",
    "preds = model(xb)\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc472d8",
   "metadata": {},
   "source": [
    "- 이제 **negative log-likelihood** 를 loss function 으로 구현해 보겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "467a91d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(y, target):\n",
    "    return -y[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a6b5d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4103, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "yb  = y_train[0: batch_size]\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec37c6af",
   "metadata": {},
   "source": [
    "- 모델의 성능을 평가하는 함수도 작성해 보겠음\n",
    "- 여기선 **정확도** 성능으로 사용. preds 중에 가장 큰 값을 갖는 index 가 target 값과 맞다면 옳은 출력이라고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bf1de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c68fb5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0938)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9136b2c",
   "metadata": {},
   "source": [
    "- 이제 training loop 를 짜볼 것\n",
    ">**For each iteration**\n",
    ">1. 데이터셋으로부터 batch_size 만큼 미니배치 추출\n",
    ">2. model 로 prediction 을 생성\n",
    ">3. prediction 과 label 을 비교하여 loss 를 계산\n",
    ">4. ```loss.backward()``` 를 이용하여 모델의 각 파라미터의 gradient를 구함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d20a168",
   "metadata": {},
   "source": [
    "- 이 gradient 를 이용해 파라미터를 업데이트\n",
    "- 파라미터를 업데이트하는 부분은 ```torch.no_grad``` 블록 안에서 진행함. 이유는 파마리터를 업데이트하는 연산이 다음 gradient 계산에 영향을 미치는 것을 방지하기 위함\n",
    "- 업데이트 후엔 해당 파라미터에 저장된 gradient 를 0으로 초기화함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ed3c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n-1) // batch_size+1):\n",
    "        start_i = i * batch_size\n",
    "        end_i = start_i + batch_size\n",
    "        xb = x_train[start_i: end_i]\n",
    "        yb = y_train[start_i: end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43a65217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0819, grad_fn=<NegBackward>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358e363a",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Using ```torch.nn.functional```\n",
    "- 파이토치의 ```nn``` 클래스를 이용하여 위 코드를 다시 작성하겠음\n",
    "- ```nn``` 의 기능을 사용할 때마다 **코드는 짧아지고, 이해하기 쉬워지며, 더 유연해질 것임**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610df577",
   "metadata": {},
   "source": [
    "- 첫 째로 수기로 작성된 활성 함수와 loss function 을 ```torch.nn.functional``` 을 이용하여 코드를 짧게 만들 수 있음\n",
    "- 해당 모듈은 다양한 loss 와 활성 함수는 물론 인공신경망을 작성하기 편하게 해주는 다양한 함수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62917be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weights + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25ccfa8",
   "metadata": {},
   "source": [
    "- 위에서 사용한 **log likelihood loss** 와 **softmax 활성함수** 를 하나로 합친 ```F.cross_entropy``` 로 대체\n",
    "- 이제 더이상 모델 안에서 활성 함수를 적지 않아도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a57ab4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0819, grad_fn=<NllLossBackward>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2317453b",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Refactor using ```nn.Module```\n",
    "- ```nn.Module, nn.Parameter``` 를 이용하여 training loop 를 좀 더 명확하고 간결하게 만들어 보겠음\n",
    "- 우리는 weight, bias 와 forward step 을 위한 메서드를 갖는 클래스를 생성하고 싶음\n",
    "- 이를 ```nn.Module``` 클래스를 상속하여 구현할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce9cf2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MNIST_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73bce9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_Logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ae637ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3626, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943866da",
   "metadata": {},
   "source": [
    "- 앞서 작성했던 training loop 부분에서 각 파라미터를 업데이트하는 부분도 간결해짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f06dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n-1) // batch_size+1):\n",
    "            start_i = i*batch_size\n",
    "            end_i = start_i + batch_size\n",
    "            xb = x_train[start_i: end_i]\n",
    "            yb = y_train[start_i: end_i]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a9a6b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0803, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885454c0",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Refactor using ```nn.Linear```\n",
    "- weight , bias 나 ```xb @ self.weights + self.bias``` 를 직접 정의하지 않고 **nn.Linear** 클래스를 선형 레이어로 생성하여 코드를 간결하게 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17e0670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19cee795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3032, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = MNIST_Logistic()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9329fe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0806, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc5e87c",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Refactor using ```optim```\n",
    "- ```torch.optim``` 은 다양한 최적화 알고리즘을 제공함\n",
    "- optimizer 의 ```step``` 메서드를 이용하면 파라미터의 업데이트가 훨씬 간편해짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c423e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3143, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0812, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "def get_model():\n",
    "    model = MNIST_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n-1) // batch_size+1):\n",
    "        start_i = i*batch_size\n",
    "        end_i = start_i + batch_size\n",
    "        xb = x_train[start_i: end_i]\n",
    "        yb = y_train[start_i: end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "            \n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e829b9",
   "metadata": {},
   "source": [
    "---\n",
    "# 7. Refactor using Dataset\n",
    "- ```len, getitem``` 메서드가 있는 모든 클래스를 파이토치의 **Dataset** 으로 사용할 수 있음\n",
    "- 파이토치의 **TensorDataset** 은 텐서를 감싼 Dateset 임\n",
    "- 데이터셋의 인덱스를 이용하여 데이터에 접근하는 방법을 쉽게 해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1f237cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a4050c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3573, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0815, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n-1) // batch_size+1):\n",
    "        start_i = i*batch_size\n",
    "        end_i = start_i + batch_size\n",
    "        xb, yb = train_ds[start_i: end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "            \n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8597291",
   "metadata": {},
   "source": [
    "---\n",
    "# 8. Refactor using DataLoader\n",
    "- ```DataLoader``` 는 어떤 ```Dataset``` 으로부터도 만들 수 있음\n",
    "- ```DataLoader``` 는 데이터셋을 배치로 iterate 하는 것을 도와줌\n",
    "- ```train_ds[start_i: end_i]``` 로 미니 배치를 갖고 오지 않고 DataLoader 를 통해 자동으로 갖고 올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76befbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl =  DataLoader(train_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f234123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0827, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c1071",
   "metadata": {},
   "source": [
    "---\n",
    "# 9. Add validation\n",
    "- 이제 validation set을 이용하여 성능을 평가하는 **Validation** 을 구현해야 함\n",
    "- 학습 데이터셋의 경우 과적합을 방지하기 위해 **데이터를 셔플하는 것이 중요했지만**\n",
    "- 검증 데이터셋의 경우 그렇지 않음. 셔플링은 시간만 더 소요될 뿐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a14672",
   "metadata": {},
   "source": [
    "- 여기선 검증셋에 대한 batch_size 를 2배 키움\n",
    "- 검증셋에 대해선 역전파할 필요가 없기 때문에(gradient 저장도 마찬가지) 배치 크기를 늘려도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "618676ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "beaf66af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.3243)\n",
      "1 tensor(0.2908)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\n",
    "        \n",
    "    print(epoch, valid_loss / len(valid_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5a48d5",
   "metadata": {},
   "source": [
    "---\n",
    "# 10. Create fit() and get_data()\n",
    "- 학습 loss 를 구할 때와 검증 loss 를 구할 때 같은 과정이 두 번 반복되므로 이를 함수화 하겠음\n",
    "- ```loss_batch``` 는 배치 데이터에 대해 loss를 계산해 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "497f53cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c08b2",
   "metadata": {},
   "source": [
    "- ```fit()``` 은 학습에 필요한 연산을 진행하고 각 에폭마다 검증셋에 대한 검증을 진행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "90bad58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(*[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl])\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb3d9e3",
   "metadata": {},
   "source": [
    "- ```get_data()``` 는 학습셋과 검증셋에 해단 dataloader 를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c4bfdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs*2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204b88c1",
   "metadata": {},
   "source": [
    "- 위 함수들을 이용해 더욱 간단하게 모델의 학습 및 검증을 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b7fd500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3238442316889763\n",
      "1 0.30318270224928856\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, batch_size)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a2503",
   "metadata": {},
   "source": [
    "---\n",
    "# 11. Switch to CNN\n",
    "- 간단한 선형 모델을 3개의 합성곱 층으로 이루어진 CNN 으로 만들어 보겠음\n",
    "- CNN으로 바꿔도 위에서 만든 함수들은 어떤 변형도 없이 그대로 사용 가능\n",
    "- 각 합성곱 층 뒤엔 ReLU 활성 함수를 붙임\n",
    "- 마지막엔 average pooling 사용 \n",
    "- torch의 ```view()``` 는 numpy의 ```reshape()``` 와 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12d2a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return xb.view(-1, xb.size(1))\n",
    "    \n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc555bb",
   "metadata": {},
   "source": [
    "- **momentum** 은 SGD 의 변종으로 대체로 학습 속도를 빠르게 해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d748652c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.31749366780519483\n",
      "1 0.23824304354190826\n"
     ]
    }
   ],
   "source": [
    "model = MNIST_CNN()\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d243537",
   "metadata": {},
   "source": [
    "---\n",
    "# 12. ```nn.Sequential```\n",
    "- ```torch.nn``` 는 **Sequential** 이라는 간편만 수기 모델 작성 클래스도 제공함\n",
    "- ```Sequential``` 객체는 담겨있는 각 모듈을 순차적으로 동작함\n",
    "- ```Sequential``` 객체를 잘 활용하려면 **사용자 정의 layer** 를 정의하여 넣으면 됨\n",
    "- 예를 들어 파이토치는 **view()** 역할을 하는 레이러를 따로 제공하지 않으므로 ```Lambda``` 층을 새로 만들어서 기능을 구현할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b190d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "    \n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d0b696",
   "metadata": {},
   "source": [
    "- 이제 ```Sequential``` 로 모델을 간단히 만들 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ea93a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.365802799320221\n",
      "1 0.25171426503658295\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(preprocess),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1))\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967a66af",
   "metadata": {},
   "source": [
    "---\n",
    "# 13. Wrapping DataLoader\n",
    "- 지금 만든 CNN 은 간단하지만 MNIST 데이터셋에서만 동작함\n",
    "- 왜냐하면 입력을 28x28 길이의 벡터만 받고 마지막 CNN 의 해상도가 4x4 로 정해져 있기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d46985",
   "metadata": {},
   "source": [
    "- 위 가정을 제거하여 **모델을 더 일반적으로 사용할 수 있게 해보겠음**\n",
    "1. 먼저 처음 Lambda 층을 제거하고 그 역할을 데이터 전처리 부분에서 대신할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae3e088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield(self.func(*b))\n",
    "            \n",
    "train_dl, vlaid_dl = get_data(train_ds, valid_ds, batch_size)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403e2f2",
   "metadata": {},
   "source": [
    "2. 다음으로 ```nn.AvgPool2d``` 를 ```nn.AdaptiveAvgPool2d``` 로 대체할 수 있음\n",
    "- 이는 입력 텐서의 사이즈가 정의되어 있지 않아 입력으로 어떤 사이즈의 데이터를 받을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5a74141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1))\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "117d464e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4577183678150177\n",
      "1 0.28313275858163833\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6028bec",
   "metadata": {},
   "source": [
    "---\n",
    "# 14. Using your GPU\n",
    "- GPU 를 사용한다면 학습을 훨씬 더 빠르게 마칠 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dba33e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb6c36d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00551c3d",
   "metadata": {},
   "source": [
    "- ```preprocess``` 함수를 수정하여 각 배치를 gpu 상으로 옮김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cdaffe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28).to(device), y.to(device)\n",
    "\n",
    "train_dl, vlaid_dl = get_data(train_ds, valid_ds, batch_size)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7b21ee",
   "metadata": {},
   "source": [
    "- 마지막으로 모델도 gpu 상으로 옮김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "66980bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0a2715",
   "metadata": {},
   "source": [
    "- 이제 학습 속도가 훨씬 빨라짐을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8a24691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.2680617673873901\n",
      "1 0.20872771389484404\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff37080e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
